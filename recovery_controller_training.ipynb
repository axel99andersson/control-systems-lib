{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMRecoveryController(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout):\n",
    "        super(LSTMRecoveryController, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2,dropout=dropout, batch_first=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc1 = nn.Linear(in_features=hidden_size, out_features=hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size // 2, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (last_h_state, last_c_state) = self.lstm(x)\n",
    "        last_h_state = last_h_state[-1,:,:]\n",
    "        x = self.fc1(last_h_state)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)*2 - 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pos</th>\n",
       "      <th>vel</th>\n",
       "      <th>est_pos</th>\n",
       "      <th>est_vel</th>\n",
       "      <th>det_est_pos</th>\n",
       "      <th>det_est_vel</th>\n",
       "      <th>measured_vel</th>\n",
       "      <th>reference_vel</th>\n",
       "      <th>ctl_signal</th>\n",
       "      <th>attack</th>\n",
       "      <th>attack_pred</th>\n",
       "      <th>residual</th>\n",
       "      <th>cusum_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.442814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.442814</td>\n",
       "      <td>0.159524</td>\n",
       "      <td>16.008867</td>\n",
       "      <td>15.461929</td>\n",
       "      <td>17.442814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.490442</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.202908</td>\n",
       "      <td>16.501936</td>\n",
       "      <td>0.159524</td>\n",
       "      <td>16.008867</td>\n",
       "      <td>0.322726</td>\n",
       "      <td>16.688765</td>\n",
       "      <td>17.360445</td>\n",
       "      <td>17.442814</td>\n",
       "      <td>0.103002</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.704115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.435625</td>\n",
       "      <td>16.518542</td>\n",
       "      <td>0.322726</td>\n",
       "      <td>16.688765</td>\n",
       "      <td>0.491437</td>\n",
       "      <td>17.099771</td>\n",
       "      <td>17.521555</td>\n",
       "      <td>17.442814</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.432567</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.588291</td>\n",
       "      <td>16.584260</td>\n",
       "      <td>0.491437</td>\n",
       "      <td>17.099771</td>\n",
       "      <td>0.663320</td>\n",
       "      <td>17.303445</td>\n",
       "      <td>17.517581</td>\n",
       "      <td>17.442814</td>\n",
       "      <td>-0.055669</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214265</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.743183</td>\n",
       "      <td>16.617385</td>\n",
       "      <td>0.663320</td>\n",
       "      <td>17.303445</td>\n",
       "      <td>0.834291</td>\n",
       "      <td>16.865072</td>\n",
       "      <td>16.313931</td>\n",
       "      <td>17.442814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.494729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time       pos        vel   est_pos    est_vel  det_est_pos  det_est_vel  \\\n",
       "0  0.00  0.000000  16.442814  0.000000  16.442814     0.159524    16.008867   \n",
       "1  0.01  0.202908  16.501936  0.159524  16.008867     0.322726    16.688765   \n",
       "2  0.02  0.435625  16.518542  0.322726  16.688765     0.491437    17.099771   \n",
       "3  0.03  0.588291  16.584260  0.491437  17.099771     0.663320    17.303445   \n",
       "4  0.04  0.743183  16.617385  0.663320  17.303445     0.834291    16.865072   \n",
       "\n",
       "   measured_vel  reference_vel  ctl_signal  attack  attack_pred  residual  \\\n",
       "0     15.461929      17.442814    1.000000   False        False -0.490442   \n",
       "1     17.360445      17.442814    0.103002   False        False  0.704115   \n",
       "2     17.521555      17.442814   -0.058896   False        False  0.432567   \n",
       "3     17.517581      17.442814   -0.055669   False        False  0.214265   \n",
       "4     16.313931      17.442814    1.000000   False        False -0.494729   \n",
       "\n",
       "   cusum_stat  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv(\"./data/ae_data.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame):\n",
    "\n",
    "    df.drop(columns=['time', 'pos', 'vel', 'est_pos', 'est_vel', 'attack', 'attack_pred', 'cusum_stat'], inplace=True)\n",
    "    df['experiment'] = df.index // 5000\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    df[['det_est_pos', 'det_est_vel', 'measured_vel', 'reference_vel', 'residual']] = scaler.fit_transform(\n",
    "        df[['det_est_pos', 'det_est_vel', 'measured_vel', 'reference_vel', 'residual']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class RecoverySequenceDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.sequences = []\n",
    "        self.labels = []\n",
    "\n",
    "        for _, group in df.groupby(\"experiment\"):\n",
    "            group = group.drop(columns=['experiment'])\n",
    "            seqs, labels = self.create_sequences(group)\n",
    "            self.sequences.extend(seqs)\n",
    "            self.labels.extend(labels)\n",
    "\n",
    "    def create_sequences(self, group):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        for i in range(len(group) - self.seq_len+1):\n",
    "            seq = group.drop(columns=['ctl_signal']).iloc[i:i+self.seq_len].values\n",
    "            label = group.ctl_signal.iloc[i+self.seq_len-1]\n",
    "            sequences.append(torch.tensor(seq, dtype=torch.float32))\n",
    "            labels.append(torch.tensor(label, dtype=torch.float32))\n",
    "        return sequences, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion, optimizer, writer: SummaryWriter, epoch: int):\n",
    "    model.train()\n",
    "    for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_out = model(x_batch)\n",
    "        loss = criterion(model_out, y_batch.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        writer.add_scalar(\"loss/train\", loss.item(), global_step=epoch*len(dataloader)+i)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def eval_model(model: nn.Module, dataloader: DataLoader, criterion, writer: SummaryWriter, epoch: int):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for i, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_out = model(x_batch)\n",
    "            loss = criterion(model_out, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    total_loss = total_loss / len(dataloader)\n",
    "    writer.add_scalar(\"loss/validation\", total_loss, global_step=epoch)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ae_data.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df = preprocess_data(df)\n",
    "ds = RecoverySequenceDataset(df, seq_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ae_data.csv')\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "train_ds = RecoverySequenceDataset(df[~df.experiment.isin([45, 46, 47, 48, 49])], seq_len=50)\n",
    "val_ds = RecoverySequenceDataset(df[df.experiment.isin([45, 46])], seq_len=50)\n",
    "# test_ds = SequenceDataset(df[df.experiment.isin([47, 48, 49])], seq_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]/home/axel/miniconda3/envs/cats/lib/python3.12/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/axel/miniconda3/envs/cats/lib/python3.12/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch: 100%|██████████| 1/1 [04:00<00:00, 240.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss: 0.7700471053460781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"./tensorboard_logs\")\n",
    "\n",
    "dataloader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=4, shuffle=True)\n",
    "# Hyperparams\n",
    "lr = 0.001\n",
    "\n",
    "# Training params\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Model, Optimizer, Loss function\n",
    "model = LSTMRecoveryController(input_size=5, hidden_size=8, dropout=0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "best_loss = float('inf')\n",
    "for epoch in tqdm(range(NUM_EPOCHS), desc=\"Epoch\"):\n",
    "    model = train_epoch(model, dataloader, criterion, optimizer, writer, epoch)\n",
    "    val_loss = eval_model(model, val_dataloader, criterion, writer, epoch)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        torch.save(model, f\"./models/recoverycontroller_ep{epoch}.pt\")\n",
    "        print(f\"Best Validation Loss: {val_loss}\")\n",
    "        best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39362/1377846169.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"./models/recoverycontroller_ep19.pt\", map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./models/recoverycontroller_ep19.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/controller_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMRecoveryController(input_size=5, hidden_size=8, dropout=0.2)\n",
    "model.load_state_dict(torch.load(\"./models/controller_weights.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = torch.rand(size=(1,5), requires_grad=False)\n",
    "datapoint = datapoint.unsqueeze(0)\n",
    "datapoint.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5898]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.58984745, dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(datapoint)\n",
    "pred[0][0].detach().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
